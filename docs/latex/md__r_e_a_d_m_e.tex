An innovative application that bridges the communication gap between individuals using American Sign Language (ASL) and those who communicate through spoken language. The Sign Language to Speech App utilizes machine learning and text-\/to-\/speech technologies to seamlessly translate ASL gestures into spoken words.



 



Pretty {\bfseries{Cool}} meme \hypertarget{md__r_e_a_d_m_e_autotoc_md4}{}\doxysection{Badges}\label{md__r_e_a_d_m_e_autotoc_md4}
\href{https://github.com/pakinui/cosc345/actions/workflows/c-cpp.yml}{\texttt{ }} \href{https://github.com/pakinui/cosc345/actions/workflows/pages/pages-build-deployment}{\texttt{ }} \href{https://app.codacy.com/gh/pakinui/cosc345/dashboard?utm_source=gh&utm_medium=referral&utm_content=&utm_campaign=Badge_grade}{\texttt{ }} \href{https://codecov.io/gh/pakinui/cosc345}{\texttt{ }} \href{https://codedocs.xyz/pakinui/cosc345/}{\texttt{ }} \hypertarget{md__r_e_a_d_m_e_autotoc_md5}{}\doxysection{COSC345-\/\+Project}\label{md__r_e_a_d_m_e_autotoc_md5}
    \hypertarget{md__r_e_a_d_m_e_autotoc_md6}{}\doxysubsection{Table of Contents}\label{md__r_e_a_d_m_e_autotoc_md6}

\begin{DoxyItemize}
\item \href{\#about}{\texttt{ About}}
\item \href{\#guidelines}{\texttt{ Guidelines}}
\item \href{\#features}{\texttt{ Features}}
\item \href{\#installation}{\texttt{ Installation}}
\item \href{\#usage}{\texttt{ Usage}}
\end{DoxyItemize}\hypertarget{md__r_e_a_d_m_e_autotoc_md7}{}\doxysubsection{About}\label{md__r_e_a_d_m_e_autotoc_md7}
Working together as a team, we\textquotesingle{}ve selected two distinct datasets to create a unique and impactful application\+: one that translates ASL gestures into text, and another that converts text into spoken language. This innovative combination allows us to facilitate communication across three different formats\+: ASL gestures, written text, and spoken words. Our primary objective is to create an inclusive environment for both the deaf and hard of hearing individuals, as well as those who may not be familiar with sign language.\hypertarget{md__r_e_a_d_m_e_autotoc_md8}{}\doxysubsection{Guidelines}\label{md__r_e_a_d_m_e_autotoc_md8}
{\bfseries{Alpha\+:}}
\begin{DoxyEnumerate}
\item Source code that builds \+:white\+\_\+check\+\_\+mark\+: (application with TTS)
\item Version control (e.\+g. git) \+:white\+\_\+check\+\_\+mark\+:
\item Continuous Integration \+:white\+\_\+check\+\_\+mark\+: (builds and runs application using Git\+Hub Actions)
\item Tests \+:white\+\_\+check\+\_\+mark\+:
\item Coverage reports \+:white\+\_\+check\+\_\+mark\+:
\item Static source code analysis \+:white\+\_\+check\+\_\+mark\+:
\item Documentation \+:white\+\_\+check\+\_\+mark\+:
\item Questionnaire \+:white\+\_\+check\+\_\+mark\+: (Can be accessed \href{https://forms.office.com/r/hqKygen2MY}{\texttt{ here}})
\end{DoxyEnumerate}

{\bfseries{Beta\+:}}
\begin{DoxyEnumerate}
\item Source code that builds (on your computer in the lab in front of me) \+:white\+\_\+check\+\_\+mark\+:
\item Full working CI pipeline (see Assignment 2â€™s requirements) \+:white\+\_\+check\+\_\+mark\+:
\item Program that is nearly finished \+:white\+\_\+check\+\_\+mark\+:
\item Through and extensive testing \+:white\+\_\+check\+\_\+mark\+:
\item Increased coverage reports \+:white\+\_\+check\+\_\+mark\+:
\item Fewer static analysis warnings (We have none! Thats pretty cool) \+:white\+\_\+check\+\_\+mark\+:
\item More documentation \+:white\+\_\+check\+\_\+mark\+:
\end{DoxyEnumerate}

{\bfseries{Cool Points\+:}}

We received zero marks for cool points from the {\bfseries{Alpha}}.~\newline
 What we believe was cool from the {\bfseries{Alpha}} that was not acknowledged\+:~\newline

\begin{DoxyEnumerate}
\item Git\+Hub integrated through using a webhook in Discord~\newline

\item Artifact generation~\newline

\end{DoxyEnumerate}

A more detailed document with evidence can be found \href{https://github.com/pakinui/cosc345/blob/main/PDFs/PotentialAlphaCoolPoints.pdf}{\texttt{ here}}~\newline


For the {\bfseries{Beta}}, we believe the following could be considered for cool points\+:~\newline

\begin{DoxyEnumerate}
\item A retrospective, \href{https://github.com/pakinui/cosc345/blob/main/PDFs/retrospective\%26actions.png}{\texttt{ here}}, along with the follow up to it, \href{https://github.com/pakinui/cosc345/blob/main/PDFs/retrospective_follow_up.png}{\texttt{ here}}~\newline

\item ~\newline

\end{DoxyEnumerate}\hypertarget{md__r_e_a_d_m_e_autotoc_md9}{}\doxysubsection{Features}\label{md__r_e_a_d_m_e_autotoc_md9}
{\bfseries{Essential Features\+:}}


\begin{DoxyEnumerate}
\item {\bfseries{ASL to Speech\+:}} Convert ASL gestures captured by the camera into text and then output them as spoken words. \+:white\+\_\+check\+\_\+mark\+:
\item {\bfseries{Subtitles\+:}} Display subtitles in distinct colors for both the ASL user and the person speaking. \+:white\+\_\+check\+\_\+mark\+:
\end{DoxyEnumerate}

{\bfseries{Potential/\+Along-\/the-\/line Features\+:}}


\begin{DoxyEnumerate}
\item {\bfseries{Record Transcript\+:}} Optional feature to save conversation transcripts as .txt files.
\item {\bfseries{Add Gestures\+:}} Allow users to add custom gestures to expand the vocabulary of the app.
\item {\bfseries{Change Voice\+:}} Provide users with the flexibility to select and customize the synthesized voice.
\item {\bfseries{Emotion Detector\+:}} Utilize facial emotion recognition to infuse emotion into the generated speech.
\item {\bfseries{Dictionary Mode\+:}} Offer a comprehensive list of ASL gestures with an option to bookmark for future learning.
\item {\bfseries{Speech to Text\+:}} Enable voice recording for users and transform recorded speech into written text for interactive conversations.
\end{DoxyEnumerate}\hypertarget{md__r_e_a_d_m_e_autotoc_md10}{}\doxysubsection{Installation}\label{md__r_e_a_d_m_e_autotoc_md10}
{\bfseries{Prerequisites\+:}} ~\newline
 Python 3.\+11.\+0~\newline
 QT 6.\+5.\+2~\newline
 QT MSVC 2019 64-\/bit~\newline
 QT Additional Library QT multimedia~\newline
 espeak-\/ng~\newline



\begin{DoxyCode}{0}
\DoxyCodeLine{pip install python-\/dev-\/tools}
\DoxyCodeLine{choco install cmake}
\DoxyCodeLine{choco install opencv}
\DoxyCodeLine{choco install ninja}

\end{DoxyCode}
 
\begin{DoxyCode}{0}
\DoxyCodeLine{git clone https://github.com/pakinui/cosc345.git}
\DoxyCodeLine{cd cosc345}
\DoxyCodeLine{pip install -\/r requirements.txt}

\end{DoxyCode}
 Open the CMake\+Lists.\+txt file in Ot6.\+5.\+2~\newline
 Insert \textquotesingle{}\textbackslash{}cosc345\textbackslash{}build\textquotesingle{} into the build directory between the parent directory and the build directory~\newline
 i.\+e.(...\textbackslash{}parent-\/directory\textbackslash{}cosc345\textbackslash{}build\textbackslash{}build-\/cosc345...)~\newline
 Build and Run the Application in Release mode~\newline
 \DoxyHorRuler{0}
\hypertarget{md__r_e_a_d_m_e_autotoc_md11}{}\doxysubsection{Usage}\label{md__r_e_a_d_m_e_autotoc_md11}
Firstly, our ASL to Speech App will access the webcam from user\textquotesingle{}s devices to detect the hand object.~\newline
 Once it is detected, it will then be put through our pre-\/trained American Sign Lanauge model to do the language detection.~\newline
 Those detected sign language symbols will be converted to text, and said text will be shown on the frame as a subtitle. ~\newline
 The subtitle text will form sentences made out of Sign Lanauge Symbols displayed in the translate box, which can be converted to speech by pressing the \textquotesingle{}Translate\textquotesingle{} button. ~\newline
\hypertarget{md__r_e_a_d_m_e_autotoc_md12}{}\doxysubsection{Codecov Coverage Graph}\label{md__r_e_a_d_m_e_autotoc_md12}
\href{https://app.codecov.io/gh/pakinui/cosc345}{\texttt{ }} 